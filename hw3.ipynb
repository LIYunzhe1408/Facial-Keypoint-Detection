{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch data\n",
    "!mkdir data\n",
    "!wget -P data/ https://s3.amazonaws.com/video.udacity-data.com/topher/2018/May/5aea1b91_train-test-data/train-test-data.zip\n",
    "!unzip -n data/train-test-data.zip -d data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need if you are using colab\n",
    "\n",
    "# !pip install matplotlib~=3.5.2\n",
    "# !pip install scikit-image==0.19.2\n",
    "# !pip install torch~=1.8.1\n",
    "# !pip install torchvision~=0.9.1\n",
    "# !pip install numpy~=1.21.6\n",
    "# !pip install pillow~=9.1.1\n",
    "# !pip install tqdm~=4.64.0\n",
    "# !pip install jupyter==1.0.0\n",
    "# !pip install opencv-python==4.6.0.66\n",
    "# !pip install pandas==1.3.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# the transforms we defined in Notebook 1 are in the helper file `custom_transforms.py`\n",
    "from custom_transforms import (\n",
    "    Rescale,\n",
    "    RandomCrop,\n",
    "    NormalizeOriginal,\n",
    "    ToTensor,\n",
    ")\n",
    "\n",
    "# the dataset we created in Notebook 1\n",
    "from facial_keypoints_dataset import FacialKeypointsDataset\n",
    "\n",
    "\n",
    "\n",
    "# defining the data_transform using transforms.Compose([all tx's, . , .])\n",
    "# order matters! i.e. rescaling should come before a smaller crop\n",
    "data_transform = transforms.Compose(\n",
    "    [Rescale(250), RandomCrop(224), NormalizeOriginal(), ToTensor()]\n",
    ")\n",
    "\n",
    "training_keypoints_csv_path = os.path.join(\"data\", \"training_frames_keypoints.csv\")\n",
    "training_data_dir = os.path.join(\"data\", \"training\")\n",
    "test_keypoints_csv_path = os.path.join(\"data\", \"test_frames_keypoints.csv\")\n",
    "test_data_dir = os.path.join(\"data\", \"test\")\n",
    "\n",
    "\n",
    "# create the transformed dataset\n",
    "transformed_dataset = FacialKeypointsDataset(\n",
    "    csv_file=training_keypoints_csv_path,\n",
    "    root_dir=training_data_dir,\n",
    "    transform=data_transform,\n",
    ")\n",
    "# load training data in batches\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(\n",
    "    transformed_dataset, batch_size=batch_size, shuffle=True, num_workers=4\n",
    ")\n",
    "\n",
    "# creating the test dataset\n",
    "test_dataset = FacialKeypointsDataset(\n",
    "    csv_file=test_keypoints_csv_path, \n",
    "    root_dir=test_data_dir, \n",
    "    transform=data_transform\n",
    ")\n",
    "# loading test data in batches\n",
    "batch_size = 16\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=True, num_workers=4\n",
    ")\n",
    "\n",
    "for i, data in enumerate(test_loader):\n",
    "    sample = data\n",
    "    image = sample['image'][0]\n",
    "    keypoints = sample['keypoints'][0]\n",
    "    # plot the image black and white\n",
    "    plt.imshow(image.numpy().transpose(1, 2, 0), cmap='gray')\n",
    "    plt.scatter(keypoints[:, 0]*50+100, keypoints[:, 1]*50+100, c='r', s=20)\n",
    "    plt.show()\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import SimpleNet, Resnet18Grayscale, Dinov2_grayscale\n",
    "\n",
    "# Defining the loss and optimization\n",
    "criterion = nn.SmoothL1Loss()\n",
    "\n",
    "net = SimpleNet()\n",
    "# net = Resnet18Grayscale()\n",
    "# net = Dinov2_grayscale()\n",
    "\n",
    "print(net)\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "def train_net(n_epochs):\n",
    "    losses = []\n",
    "    # prepare the net for training\n",
    "    net.train()\n",
    "    net.cuda()\n",
    "\n",
    "    # loop over the dataset multiple times\n",
    "    for epoch in tqdm(range(n_epochs), desc=\"training\"):\n",
    "\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # train on batches of data, assumes we already have train_loader\n",
    "        batch_i = 0\n",
    "        for data in tqdm(train_loader, desc=\"epoch {}\".format(epoch)):\n",
    "\n",
    "            # get the input images and their corresponding labels\n",
    "            images = data[\"image\"]\n",
    "            key_pts = data[\"keypoints\"]\n",
    "\n",
    "            # TODO: implement training code here\n",
    "            \n",
    "            # print loss statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            batch_i += 1\n",
    "\n",
    "    return losses\n",
    "    print(\"Finished Training\")\n",
    "\n",
    "# train the network\n",
    "n_epochs = 10  # we start at small values, then we increase when we fixed the model structure and hyperparams\n",
    "\n",
    "losses = train_net(n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_all_keypoints(image, predicted_key_pts, gt_pts=None):\n",
    "    \"\"\"\n",
    "    Show image with predicted keypoints and optionally ground truth keypoints\n",
    "    \"\"\"\n",
    "    # Convert grayscale to RGB if needed\n",
    "    if len(image.shape) == 2:\n",
    "        image = np.stack([image]*3, axis=2)\n",
    "    \n",
    "    plt.imshow(image*255, cmap='gray')\n",
    "    plt.scatter(predicted_key_pts[:, 0], predicted_key_pts[:, 1], s=20, marker='.', c='m')\n",
    "    \n",
    "    if gt_pts is not None:\n",
    "        plt.scatter(gt_pts[:, 0], gt_pts[:, 1], s=20, marker='.', c='g')\n",
    "\n",
    "\n",
    "# test the model on a batch of test images\n",
    "def net_sample_output(model, test_loader):\n",
    "\n",
    "    # iterate through the test dataset\n",
    "    for i, sample in enumerate(test_loader):\n",
    "\n",
    "        # getting sample data: images and ground truth keypoints\n",
    "        images = sample[\"image\"]\n",
    "        key_pts = sample[\"keypoints\"]\n",
    "\n",
    "        # converting images to FloatTensors\n",
    "        images = images.type(torch.FloatTensor)\n",
    "\n",
    "        # forwarding pass to get net output\n",
    "        output_pts = model(images)\n",
    "\n",
    "        # reshaping to batch_size x 68 x 2 pts # (136*1) => (68*2)\n",
    "        output_pts = output_pts.view(output_pts.size()[0], 68, -1)\n",
    "\n",
    "        # break after first image is tested\n",
    "        if i == 0:\n",
    "            return (\n",
    "                images,\n",
    "                output_pts,\n",
    "                key_pts,\n",
    "            )  # images, predicted key points, real keypoints\n",
    "\n",
    "# visualize the output\n",
    "# by default this shows a batch of 10 images\n",
    "def visualize_output(test_images, test_outputs, gt_pts=None, batch_size=10):\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    for i in range(batch_size):\n",
    "        ax = plt.subplot(batch_size // 5, 5, i + 1)\n",
    "\n",
    "        # un-transform the image data\n",
    "        image = test_images[i].data  # get the image from its Variable wrapper\n",
    "        image = image.numpy()  # convert to numpy array from a Tensor\n",
    "        image = np.transpose(\n",
    "            image, (1, 2, 0)\n",
    "        )  # transpose to go from torch to numpy image\n",
    "\n",
    "        # un-transform the predicted key_pts data\n",
    "        predicted_key_pts = test_outputs[i].data\n",
    "        predicted_key_pts = predicted_key_pts.numpy()\n",
    "\n",
    "        # undo normalization of keypoints\n",
    "        predicted_key_pts = predicted_key_pts * 50.0 + 100\n",
    "\n",
    "        # plot ground truth points for comparison, if they exist\n",
    "        ground_truth_pts = None\n",
    "        if gt_pts is not None:\n",
    "            ground_truth_pts = gt_pts[i]\n",
    "            ground_truth_pts = ground_truth_pts * 50.0 + 100\n",
    "\n",
    "        # call show_all_keypoints\n",
    "        show_all_keypoints(np.squeeze(image), predicted_key_pts, ground_truth_pts)\n",
    "\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Smooth L1 Loss\")\n",
    "plt.plot(losses, \"g-\")\n",
    "\n",
    "# get a sample of test data again\n",
    "test_images, test_outputs, gt_pts = net_sample_output(net.cpu(), test_loader)\n",
    "\n",
    "print(test_images.data.size())\n",
    "print(test_outputs.data.size())\n",
    "print(gt_pts.size())\n",
    "\n",
    "# visualize the test output\n",
    "visualize_output(test_images, test_outputs, gt_pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training UNet with Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# the transforms we defined in Notebook 1 are in the helper file `custom_transforms.py`\n",
    "from custom_transforms import (\n",
    "    Rescale,\n",
    "    RandomCrop,\n",
    "    NormalizeOriginal,\n",
    "    ToTensor,\n",
    ")\n",
    "\n",
    "# the dataset we created in Notebook 1\n",
    "from facial_keypoints_dataset import FacialKeypointsHeatmapDataset\n",
    "\n",
    "\n",
    "\n",
    "# defining the data_transform using transforms.Compose([all tx's, . , .])\n",
    "# order matters! i.e. rescaling should come before a smaller crop\n",
    "data_transform = transforms.Compose(\n",
    "    [Rescale(250), RandomCrop(224), NormalizeOriginal(), ToTensor()]\n",
    ")\n",
    "\n",
    "training_keypoints_csv_path = os.path.join(\"data\", \"training_frames_keypoints.csv\")\n",
    "training_data_dir = os.path.join(\"data\", \"training\")\n",
    "test_keypoints_csv_path = os.path.join(\"data\", \"test_frames_keypoints.csv\")\n",
    "test_data_dir = os.path.join(\"data\", \"test\")\n",
    "\n",
    "\n",
    "# create the transformed dataset\n",
    "transformed_dataset = FacialKeypointsHeatmapDataset(\n",
    "    csv_file=training_keypoints_csv_path,\n",
    "    root_dir=training_data_dir,\n",
    "    transform=data_transform,\n",
    "    output_size=224\n",
    ")\n",
    "# load training data in batches\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(\n",
    "    transformed_dataset, batch_size=batch_size, shuffle=True, num_workers=4\n",
    ")\n",
    "\n",
    "# creating the test dataset\n",
    "test_dataset = FacialKeypointsHeatmapDataset(\n",
    "    csv_file=test_keypoints_csv_path, \n",
    "    root_dir=test_data_dir, \n",
    "    transform=data_transform,\n",
    "    output_size=224\n",
    ")\n",
    "# loading test data in batches\n",
    "batch_size = 16\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=True, num_workers=4\n",
    ")\n",
    "\n",
    "for i, data in enumerate(test_loader):\n",
    "    sample = data\n",
    "    image = sample['image'][0]\n",
    "    keypoints = sample['keypoints'][0]\n",
    "    # plot the image\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image.numpy().transpose(1, 2, 0), cmap='gray')\n",
    "    plt.scatter(keypoints[:, 0]*50+100, keypoints[:, 1]*50+100, c='r', s=20)\n",
    "    # show the heatmaps\n",
    "    plt.subplot(1, 2, 2)\n",
    "    heatmaps = sample['heatmaps'][0].sum(dim=0, keepdim=True)\n",
    "    plt.imshow(heatmaps.numpy().transpose(1, 2, 0))\n",
    "    plt.show()\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: training code for UNet with heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: visualize your predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chewbacca_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
